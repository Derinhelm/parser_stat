{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Derinhelm/parser_stat/blob/main/parser_running.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQpB65N5z79d"
   },
   "source": [
    "# Code downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_GSFZQ1rd9m",
    "outputId": "76f2a782-b7c9-44e1-aa9d-50835adf95a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'parser_stat'...\n",
      "remote: Enumerating objects: 63, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
      "remote: Total 63 (delta 30), reused 36 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (63/63), 14.17 MiB | 13.71 MiB/s, done.\n",
      "Resolving deltas: 100% (30/30), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b tokenization_changing https://github.com/Derinhelm/parser_stat.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwS2uPLzrp8l"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/parser_stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rCMCNnD0iDV"
   },
   "source": [
    "# Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jf-9gGT99CdG"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WF95eNWm9CWL"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LpFrgGGT0TQ"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZZGZbmk0khj"
   },
   "outputs": [],
   "source": [
    "!apt install python3.10-venv\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZUulp-k5rlG"
   },
   "source": [
    "# UDPipe with CONLL tokenisation running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy87eoje6BXS"
   },
   "outputs": [],
   "source": [
    "!python3 -m venv udpipe_env; source udpipe_env/bin/activate; pip install spacy-udpipe==1.0.0\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftgj-9fq68Nj",
    "outputId": "f7c9bc1c-90a7-4254-e09b-70cda1fbb272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/udpipe_env/bin/python\n",
      "/content/parser_stat/treebank_test_sets/treebank_data.pickle\n",
      "udpipe\n",
      "Downloaded pre-trained UDPipe model for 'ru' language\n",
      "\n",
      " gsd\n",
      "   0/601\n",
      " 100/601\n",
      " 200/601\n",
      " 300/601\n",
      " 400/601\n",
      " 500/601\n",
      " 600/601\n",
      "\n",
      " pud\n",
      "   0/1000\n",
      " 100/1000\n",
      " 200/1000\n",
      " 300/1000\n",
      " 400/1000\n",
      " 500/1000\n",
      " 600/1000\n",
      " 700/1000\n",
      " 800/1000\n",
      " 900/1000\n",
      "\n",
      " syntagrus\n",
      "   0/8800\n",
      " 100/8800\n",
      " 200/8800\n",
      " 300/8800\n",
      " 400/8800\n",
      " 500/8800\n",
      " 600/8800\n",
      " 700/8800\n",
      " 800/8800\n",
      " 900/8800\n",
      "1000/8800\n",
      "1100/8800\n",
      "1200/8800\n",
      "1300/8800\n",
      "1400/8800\n",
      "1500/8800\n",
      "1600/8800\n",
      "1700/8800\n",
      "1800/8800\n",
      "1900/8800\n",
      "2000/8800\n",
      "2100/8800\n",
      "2200/8800\n",
      "2300/8800\n",
      "2400/8800\n",
      "2500/8800\n",
      "2600/8800\n",
      "2700/8800\n",
      "2800/8800\n",
      "2900/8800\n",
      "3000/8800\n",
      "3100/8800\n",
      "3200/8800\n",
      "3300/8800\n",
      "3400/8800\n",
      "3500/8800\n",
      "3600/8800\n",
      "3700/8800\n",
      "3800/8800\n",
      "3900/8800\n",
      "4000/8800\n",
      "4100/8800\n",
      "4200/8800\n",
      "4300/8800\n",
      "4400/8800\n",
      "4500/8800\n",
      "4600/8800\n",
      "4700/8800\n",
      "4800/8800\n",
      "4900/8800\n",
      "5000/8800\n",
      "5100/8800\n",
      "5200/8800\n",
      "5300/8800\n",
      "5400/8800\n",
      "5500/8800\n",
      "5600/8800\n",
      "5700/8800\n",
      "5800/8800\n",
      "5900/8800\n",
      "6000/8800\n",
      "6100/8800\n",
      "6200/8800\n",
      "6300/8800\n",
      "6400/8800\n",
      "6500/8800\n",
      "6600/8800\n",
      "6700/8800\n",
      "6800/8800\n",
      "6900/8800\n",
      "7000/8800\n",
      "7100/8800\n",
      "7200/8800\n",
      "7300/8800\n",
      "7400/8800\n",
      "7500/8800\n",
      "7600/8800\n",
      "7700/8800\n",
      "7800/8800\n",
      "7900/8800\n",
      "8000/8800\n",
      "8100/8800\n",
      "8200/8800\n",
      "8300/8800\n",
      "8400/8800\n",
      "8500/8800\n",
      "8600/8800\n",
      "8700/8800\n",
      "\n",
      " poetry\n",
      "   0/728\n",
      " 100/728\n",
      " 200/728\n",
      " 300/728\n",
      " 400/728\n",
      " 500/728\n",
      " 600/728\n",
      " 700/728\n",
      "\n",
      " taiga\n",
      "   0/881\n",
      " 100/881\n",
      " 200/881\n",
      " 300/881\n",
      " 400/881\n",
      " 500/881\n",
      " 600/881\n",
      " 700/881\n",
      " 800/881\n",
      "\n",
      "time results (s):\n",
      "gsd       : 10.036 (s)\n",
      "pud       : 18.135 (s)\n",
      "syntagrus : 137.007 (s)\n",
      "poetry    : 8.961 (s)\n",
      "taiga     : 8.741 (s)\n"
     ]
    }
   ],
   "source": [
    "!source /content/udpipe_env/bin/activate; which python; \\\n",
    "    python3 /content/parser_stat/parser_running.py /content/parser_stat/treebank_test_sets/treebank_data.pickle udpipe_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "aHNcddoA6CH5",
    "outputId": "088a87ad-15aa-46e5-a521-197826b4f0f7"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e5c63106-b790-43e9-8e75-fdd119943fcd\", \"udpipe.pickle\", 15452693)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"/content/udpipe_t.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd8A4DmY5rdK"
   },
   "source": [
    "# Stanza with CONLL tokenisation running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ9Q2cAu6LW4"
   },
   "outputs": [],
   "source": [
    "!python3 -m venv stanza_env; source stanza_env/bin/activate; \\\n",
    "    which python; pip install stanza==1.8.1\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1_5tZ_K7q9o",
    "outputId": "c49cc602-ca86-4e95-90e3-2ff374639df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/stanza_env/bin/python\n",
      "/content/parser_stat/treebank_test_sets/treebank_data.pickle\n",
      "stanza\n",
      "2024-10-06 05:41:24 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 39.3MB/s]        \n",
      "2024-10-06 05:41:24 INFO: Downloaded file to /root/stanza_resources/resources.json\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/tokenize/syntagrus.pt: 100% 641k/641k [00:00<00:00, 12.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/pos/syntagrus_charlm.pt: 100% 38.8M/38.8M [00:00<00:00, 211MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/lemma/syntagrus_nocharlm.pt: 100% 13.5M/13.5M [00:00<00:00, 125MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/depparse/syntagrus_charlm.pt: 100% 147M/147M [00:00<00:00, 241MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/forward_charlm/newswiki.pt: 100% 20.0M/20.0M [00:00<00:00, 147MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/backward_charlm/newswiki.pt: 100% 20.0M/20.0M [00:00<00:00, 128MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 109M/109M [00:00<00:00, 204MB/s] \n",
      "2024-10-06 05:41:29 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| pos       | syntagrus_charlm   |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "| depparse  | syntagrus_charlm   |\n",
      "==================================\n",
      "\n",
      "2024-10-06 05:41:29 INFO: Using device: cpu\n",
      "2024-10-06 05:41:29 INFO: Loading: tokenize\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-06 05:41:31 INFO: Loading: pos\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/pos/trainer.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-06 05:41:32 INFO: Loading: lemma\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-06 05:41:32 INFO: Loading: depparse\n",
      "/content/stanza_env/lib/python3.10/site-packages/stanza/models/depparse/trainer.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-10-06 05:41:32 INFO: Done loading processors!\n",
      "\n",
      " gsd\n",
      "   0/601\n",
      " 100/601\n",
      " 200/601\n",
      " 300/601\n",
      " 400/601\n",
      " 500/601\n",
      " 600/601\n",
      "\n",
      " pud\n",
      "   0/1000\n",
      " 100/1000\n",
      " 200/1000\n",
      " 300/1000\n",
      " 400/1000\n",
      " 500/1000\n",
      " 600/1000\n",
      " 700/1000\n",
      " 800/1000\n",
      " 900/1000\n",
      "\n",
      " syntagrus\n",
      "   0/8800\n",
      " 100/8800\n",
      " 200/8800\n",
      " 300/8800\n",
      " 400/8800\n",
      " 500/8800\n",
      " 600/8800\n",
      " 700/8800\n",
      " 800/8800\n",
      " 900/8800\n",
      "1000/8800\n",
      "1100/8800\n",
      "1200/8800\n",
      "1300/8800\n",
      "1400/8800\n",
      "1500/8800\n",
      "1600/8800\n",
      "1700/8800\n",
      "1800/8800\n",
      "1900/8800\n",
      "2000/8800\n",
      "2100/8800\n",
      "2200/8800\n",
      "2300/8800\n",
      "2400/8800\n",
      "2500/8800\n",
      "2600/8800\n",
      "2700/8800\n",
      "2800/8800\n",
      "2900/8800\n",
      "3000/8800\n",
      "3100/8800\n",
      "3200/8800\n",
      "3300/8800\n",
      "3400/8800\n",
      "3500/8800\n",
      "3600/8800\n",
      "3700/8800\n",
      "3800/8800\n",
      "3900/8800\n",
      "4000/8800\n",
      "4100/8800\n",
      "4200/8800\n",
      "4300/8800\n",
      "4400/8800\n",
      "4500/8800\n",
      "4600/8800\n",
      "4700/8800\n",
      "4800/8800\n",
      "4900/8800\n",
      "5000/8800\n",
      "5100/8800\n",
      "5200/8800\n",
      "5300/8800\n",
      "5400/8800\n",
      "5500/8800\n",
      "5600/8800\n",
      "5700/8800\n",
      "5800/8800\n",
      "5900/8800\n",
      "6000/8800\n",
      "6100/8800\n",
      "6200/8800\n",
      "6300/8800\n",
      "6400/8800\n",
      "6500/8800\n",
      "6600/8800\n",
      "6700/8800\n",
      "6800/8800\n",
      "6900/8800\n",
      "7000/8800\n",
      "7100/8800\n",
      "7200/8800\n",
      "7300/8800\n",
      "7400/8800\n",
      "7500/8800\n",
      "7600/8800\n",
      "7700/8800\n",
      "7800/8800\n",
      "7900/8800\n",
      "8000/8800\n",
      "8100/8800\n",
      "8200/8800\n",
      "8300/8800\n",
      "8400/8800\n",
      "8500/8800\n",
      "8600/8800\n",
      "8700/8800\n",
      "\n",
      " poetry\n",
      "   0/728\n",
      " 100/728\n",
      " 200/728\n",
      " 300/728\n",
      " 400/728\n",
      " 500/728\n",
      " 600/728\n",
      " 700/728\n",
      "\n",
      " taiga\n",
      "   0/881\n",
      " 100/881\n",
      " 200/881\n",
      " 300/881\n",
      " 400/881\n",
      " 500/881\n",
      " 600/881\n",
      " 700/881\n",
      " 800/881\n",
      "\n",
      "time results (s):\n",
      "gsd       : 481.504 (s)\n",
      "pud       : 830.284 (s)\n",
      "syntagrus : 7495.900 (s)\n",
      "poetry    : 469.055 (s)\n",
      "taiga     : 532.078 (s)\n"
     ]
    }
   ],
   "source": [
    "!source /content/stanza_env/bin/activate; which python;\\\n",
    "    python3 /content/parser_stat/parser_running.py /content/parser_stat/treebank_test_sets/treebank_data.pickle stanza_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "vXeRnp0p6LTb",
    "outputId": "cdcca06e-4fa0-4a92-c8f3-74f2010fad2a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_6e3e886b-b1c2-47fe-bbb6-d8347c6f2d27\", \"stanza.pickle\", 15294166)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"/content/stanza_t.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeWxzx7K0BCg"
   },
   "source": [
    "# Natasha with CONLL tokenisation running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRxPSi1Y0aLV"
   },
   "outputs": [],
   "source": [
    "!python3 -m venv natasha_env; source natasha_env/bin/activate; \\\n",
    "    which python; pip install natasha==1.6.0\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PN5LGlW70hY",
    "outputId": "9e9e34de-350a-4dee-908b-e80c5cf2acf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/natasha_env/bin/python\n",
      "/content/parser_stat/treebank_test_sets/treebank_data.pickle\n",
      "natasha\n",
      "\n",
      " gsd\n",
      "   0/601\n",
      " 100/601\n",
      " 200/601\n",
      " 300/601\n",
      " 400/601\n",
      " 500/601\n",
      " 600/601\n",
      "\n",
      " pud\n",
      "   0/1000\n",
      " 100/1000\n",
      " 200/1000\n",
      " 300/1000\n",
      " 400/1000\n",
      " 500/1000\n",
      " 600/1000\n",
      " 700/1000\n",
      " 800/1000\n",
      " 900/1000\n",
      "\n",
      " syntagrus\n",
      "   0/8800\n",
      " 100/8800\n",
      " 200/8800\n",
      " 300/8800\n",
      " 400/8800\n",
      " 500/8800\n",
      " 600/8800\n",
      " 700/8800\n",
      " 800/8800\n",
      " 900/8800\n",
      "1000/8800\n",
      "1100/8800\n",
      "1200/8800\n",
      "1300/8800\n",
      "1400/8800\n",
      "1500/8800\n",
      "1600/8800\n",
      "1700/8800\n",
      "1800/8800\n",
      "1900/8800\n",
      "2000/8800\n",
      "2100/8800\n",
      "2200/8800\n",
      "2300/8800\n",
      "2400/8800\n",
      "2500/8800\n",
      "2600/8800\n",
      "2700/8800\n",
      "2800/8800\n",
      "2900/8800\n",
      "3000/8800\n",
      "3100/8800\n",
      "3200/8800\n",
      "3300/8800\n",
      "3400/8800\n",
      "3500/8800\n",
      "3600/8800\n",
      "3700/8800\n",
      "3800/8800\n",
      "3900/8800\n",
      "4000/8800\n",
      "4100/8800\n",
      "4200/8800\n",
      "4300/8800\n",
      "4400/8800\n",
      "4500/8800\n",
      "4600/8800\n",
      "4700/8800\n",
      "4800/8800\n",
      "4900/8800\n",
      "5000/8800\n",
      "5100/8800\n",
      "5200/8800\n",
      "5300/8800\n",
      "5400/8800\n",
      "5500/8800\n",
      "5600/8800\n",
      "5700/8800\n",
      "5800/8800\n",
      "5900/8800\n",
      "6000/8800\n",
      "6100/8800\n",
      "6200/8800\n",
      "6300/8800\n",
      "6400/8800\n",
      "6500/8800\n",
      "6600/8800\n",
      "6700/8800\n",
      "6800/8800\n",
      "6900/8800\n",
      "7000/8800\n",
      "7100/8800\n",
      "7200/8800\n",
      "7300/8800\n",
      "7400/8800\n",
      "7500/8800\n",
      "7600/8800\n",
      "7700/8800\n",
      "7800/8800\n",
      "7900/8800\n",
      "8000/8800\n",
      "8100/8800\n",
      "8200/8800\n",
      "8300/8800\n",
      "8400/8800\n",
      "8500/8800\n",
      "8600/8800\n",
      "8700/8800\n",
      "\n",
      " poetry\n",
      "   0/728\n",
      " 100/728\n",
      " 200/728\n",
      " 300/728\n",
      " 400/728\n",
      " 500/728\n",
      " 600/728\n",
      " 700/728\n",
      "\n",
      " taiga\n",
      "   0/881\n",
      " 100/881\n",
      " 200/881\n",
      " 300/881\n",
      " 400/881\n",
      " 500/881\n",
      " 600/881\n",
      " 700/881\n",
      " 800/881\n",
      "\n",
      "time results (s):\n",
      "gsd       : 3.267 (s)\n",
      "pud       : 4.613 (s)\n",
      "syntagrus : 49.834 (s)\n",
      "poetry    : 2.908 (s)\n",
      "taiga     : 3.381 (s)\n"
     ]
    }
   ],
   "source": [
    "!source /content/natasha_env/bin/activate; which python; \\\n",
    "    python3 /content/parser_stat/parser_running.py /content/parser_stat/treebank_test_sets/treebank_data.pickle natasha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "xMFjXdWired5",
    "outputId": "aa6a213f-8b3c-4197-e962-b7b834476a9d"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e599783a-4146-4e6a-937f-90e7242843db\", \"natasha.pickle\", 14868933)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"/content/natasha_t.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGTB3YRt5xhd"
   },
   "source": [
    "# DeepPavlov with CONLL tokenisation running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFgqP6rK6SQM"
   },
   "outputs": [],
   "source": [
    "!python3 -m venv deeppavlov_env; source deeppavlov_env/bin/activate; \\\n",
    "    which python; pip install deeppavlov==1.6.0\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO8eR3Lu7_t4",
    "outputId": "90b9c739-be19-439a-9bbd-7b6c8c0ccdc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/deeppavlov_env/bin/python\n",
      "/content/parser_stat/treebank_test_sets/treebank_data.pickle\n",
      "deeppavlov\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "Collecting pytorch-crf==0.7.*\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n",
      "Ignoring transformers: markers 'python_version < \"3.8\"' don't match your environment\n",
      "Collecting transformers==4.30.0\n",
      "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in ./deeppavlov_env/lib/python3.10/site-packages (from transformers==4.30.0) (2024.9.11)\n",
      "Requirement already satisfied: requests in ./deeppavlov_env/lib/python3.10/site-packages (from transformers==4.30.0) (2.32.3)\n",
      "Requirement already satisfied: filelock in ./deeppavlov_env/lib/python3.10/site-packages (from transformers==4.30.0) (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./deeppavlov_env/lib/python3.10/site-packages (from transformers==4.30.0) (4.64.1)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./deeppavlov_env/lib/python3.10/site-packages (from transformers==4.30.0) (1.23.5)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in ./deeppavlov_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.12.2)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./deeppavlov_env/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./deeppavlov_env/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./deeppavlov_env/lib/python3.10/site-packages (from requests->transformers==4.30.0) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./deeppavlov_env/lib/python3.10/site-packages (from requests->transformers==4.30.0) (3.3.2)\n",
      "Installing collected packages: tokenizers, safetensors, pyyaml, packaging, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2024.9.0 huggingface-hub-0.25.1 packaging-24.1 pyyaml-6.0.2 safetensors-0.4.5 tokenizers-0.13.3 transformers-4.30.0\n",
      "Collecting torch<1.14.0,>=1.6.0\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./deeppavlov_env/lib/python3.10/site-packages (from torch<1.14.0,>=1.6.0) (4.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in ./deeppavlov_env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (0.44.0)\n",
      "Requirement already satisfied: setuptools in ./deeppavlov_env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.14.0,>=1.6.0) (59.6.0)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n",
      "Collecting ufal.chu-liu-edmonds\n",
      "  Downloading ufal.chu_liu_edmonds-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ufal.chu-liu-edmonds\n",
      "Successfully installed ufal.chu-liu-edmonds-1.0.3\n",
      "2024-10-06 08:50:21.714 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/deeppavlov_data/syntax_parsing/rus_6layers.tar.gz to /root/.deeppavlov/models/syntax_parsing/rus_6layers.tar.gz\n",
      "100% 1.71G/1.71G [00:58<00:00, 29.0MB/s]\n",
      "2024-10-06 08:51:21.414 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting /root/.deeppavlov/models/syntax_parsing/rus_6layers.tar.gz archive into /root/.deeppavlov/models/syntax_parsing/rus_6layers\n",
      "2024-10-06 08:51:52.713 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/deeppavlov_data/morpho_tagger/UD2.3/ru_syntagrus.tar.gz to /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus.tar.gz\n",
      "100% 16.7M/16.7M [00:01<00:00, 12.4MB/s]\n",
      "2024-10-06 08:51:54.794 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus.tar.gz archive into /root/.deeppavlov/downloads/UD2.3_source/ru_syntagrus\n",
      "/content/deeppavlov_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "tokenizer_config.json: 100% 24.0/24.0 [00:00<00:00, 75.1kB/s]\n",
      "config.json: 100% 642/642 [00:00<00:00, 3.04MB/s]\n",
      "vocab.txt: 100% 1.65M/1.65M [00:00<00:00, 7.47MB/s]\n",
      "special_tokens_map.json: 100% 112/112 [00:00<00:00, 433kB/s]\n",
      "pytorch_model.bin: 100% 714M/714M [00:06<00:00, 113MB/s]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2024-10-06 08:52:13.626 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersSyntaxParser on GPU, since no CUDA GPUs are available. Using CPU.\n",
      "\n",
      " gsd\n",
      "   0/601\n",
      " 100/601\n",
      " 200/601\n",
      " 300/601\n",
      " 400/601\n",
      " 500/601\n",
      " 600/601\n",
      "\n",
      " pud\n",
      "   0/1000\n",
      " 100/1000\n",
      " 200/1000\n",
      " 300/1000\n",
      " 400/1000\n",
      " 500/1000\n",
      " 600/1000\n",
      " 700/1000\n",
      " 800/1000\n",
      " 900/1000\n",
      "\n",
      " syntagrus\n",
      "   0/8800\n",
      " 100/8800\n",
      " 200/8800\n",
      " 300/8800\n",
      " 400/8800\n",
      " 500/8800\n",
      " 600/8800\n",
      " 700/8800\n",
      " 800/8800\n",
      " 900/8800\n",
      "1000/8800\n",
      "1100/8800\n",
      "1200/8800\n",
      "1300/8800\n",
      "1400/8800\n",
      "1500/8800\n",
      "1600/8800\n",
      "1700/8800\n",
      "1800/8800\n",
      "1900/8800\n",
      "2000/8800\n",
      "2100/8800\n",
      "2200/8800\n",
      "2300/8800\n",
      "2400/8800\n",
      "2500/8800\n",
      "2600/8800\n",
      "2700/8800\n",
      "2800/8800\n",
      "2900/8800\n",
      "3000/8800\n",
      "3100/8800\n",
      "3200/8800\n",
      "3300/8800\n",
      "3400/8800\n",
      "3500/8800\n",
      "3600/8800\n",
      "3700/8800\n",
      "3800/8800\n",
      "3900/8800\n",
      "4000/8800\n",
      "4100/8800\n",
      "4200/8800\n",
      "4300/8800\n",
      "4400/8800\n",
      "4500/8800\n",
      "4600/8800\n",
      "4700/8800\n",
      "4800/8800\n",
      "4900/8800\n",
      "5000/8800\n",
      "5100/8800\n",
      "5200/8800\n",
      "5300/8800\n",
      "5400/8800\n",
      "5500/8800\n",
      "5600/8800\n",
      "5700/8800\n",
      "5800/8800\n",
      "5900/8800\n",
      "6000/8800\n",
      "6100/8800\n",
      "6200/8800\n",
      "6300/8800\n",
      "6400/8800\n",
      "6500/8800\n",
      "6600/8800\n",
      "6700/8800\n",
      "6800/8800\n",
      "6900/8800\n",
      "7000/8800\n",
      "7100/8800\n",
      "7200/8800\n",
      "7300/8800\n",
      "7400/8800\n",
      "7500/8800\n",
      "7600/8800\n",
      "7700/8800\n",
      "7800/8800\n",
      "7900/8800\n",
      "8000/8800\n",
      "8100/8800\n",
      "8200/8800\n",
      "8300/8800\n",
      "8400/8800\n",
      "8500/8800\n",
      "8600/8800\n",
      "8700/8800\n",
      "\n",
      " poetry\n",
      "   0/728\n",
      " 100/728\n",
      " 200/728\n",
      " 300/728\n",
      " 400/728\n",
      " 500/728\n",
      " 600/728\n",
      " 700/728\n",
      "\n",
      " taiga\n",
      "   0/881\n",
      " 100/881\n",
      " 200/881\n",
      " 300/881\n",
      " 400/881\n",
      " 500/881\n",
      " 600/881\n",
      " 700/881\n",
      " 800/881\n",
      "\n",
      "time results (s):\n",
      "gsd       : 131.280 (s)\n",
      "pud       : 193.175 (s)\n",
      "syntagrus : 1613.516 (s)\n",
      "poetry    : 118.674 (s)\n",
      "taiga     : 130.404 (s)\n"
     ]
    }
   ],
   "source": [
    "!source /content/deeppavlov_env/bin/activate; which python; \\\n",
    "    python3 /content/parser_stat/parser_running.py /content/parser_stat/treebank_test_sets/treebank_data.pickle deeppavlov_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "j0KhY2gq6SNk",
    "outputId": "61d228c2-85a4-411a-b6be-5a8acf1669b8"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_77d8ddff-53ed-4647-b6df-032b0c0205ad\", \"deeppavlov.pickle\", 15810376)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"/content/deeppavlov_t.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9nHzene5xdb"
   },
   "source": [
    "# spacy with CONLL tokenisation running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUOZLzR9sWUB"
   },
   "outputs": [],
   "source": [
    "!python3 -m venv spacy_env; source spacy_env/bin/activate; \\\n",
    "    which python; pip install spacy==3.7.5\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYy8Izwn8I-H",
    "outputId": "b42d5055-153e-458a-8e54-5627c77d79a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/spacy_env/bin/python\n",
      "Collecting ru-core-news-lg==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_lg-3.7.0/ru_core_news_lg-3.7.0-py3-none-any.whl (513.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./spacy_env/lib/python3.10/site-packages (from ru-core-news-lg==3.7.0) (3.7.5)\n",
      "Collecting pymorphy3>=1.0.0\n",
      "  Downloading pymorphy3-2.0.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pymorphy3-dicts-ru\n",
      "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.9.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (24.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.12.5)\n",
      "Requirement already satisfied: setuptools in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (59.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.66.5)\n",
      "Requirement already satisfied: jinja2 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./spacy_env/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in ./spacy_env/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./spacy_env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./spacy_env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./spacy_env/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./spacy_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./spacy_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./spacy_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./spacy_env/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2024.8.30)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./spacy_env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./spacy_env/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./spacy_env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./spacy_env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (13.9.2)\n",
      "Requirement already satisfied: click>=8.0.0 in ./spacy_env/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./spacy_env/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./spacy_env/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./spacy_env/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in ./spacy_env/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./spacy_env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./spacy_env/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: wrapt in ./spacy_env/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./spacy_env/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-lg==3.7.0) (0.1.2)\n",
      "Installing collected packages: pymorphy3-dicts-ru, dawg-python, pymorphy3, ru-core-news-lg\n",
      "Successfully installed dawg-python-0.7.2 pymorphy3-2.0.2 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-lg-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_lg')\n",
      "/content/parser_stat/treebank_test_sets/treebank_data.pickle\n",
      "spacy\n",
      "\n",
      " gsd\n",
      "   0/601\n",
      " 100/601\n",
      " 200/601\n",
      " 300/601\n",
      " 400/601\n",
      " 500/601\n",
      " 600/601\n",
      "\n",
      " pud\n",
      "   0/1000\n",
      " 100/1000\n",
      " 200/1000\n",
      " 300/1000\n",
      " 400/1000\n",
      " 500/1000\n",
      " 600/1000\n",
      " 700/1000\n",
      " 800/1000\n",
      " 900/1000\n",
      "\n",
      " syntagrus\n",
      "   0/8800\n",
      " 100/8800\n",
      " 200/8800\n",
      " 300/8800\n",
      " 400/8800\n",
      " 500/8800\n",
      " 600/8800\n",
      " 700/8800\n",
      " 800/8800\n",
      " 900/8800\n",
      "1000/8800\n",
      "1100/8800\n",
      "1200/8800\n",
      "1300/8800\n",
      "1400/8800\n",
      "1500/8800\n",
      "1600/8800\n",
      "1700/8800\n",
      "1800/8800\n",
      "1900/8800\n",
      "2000/8800\n",
      "2100/8800\n",
      "2200/8800\n",
      "2300/8800\n",
      "2400/8800\n",
      "2500/8800\n",
      "2600/8800\n",
      "2700/8800\n",
      "2800/8800\n",
      "2900/8800\n",
      "3000/8800\n",
      "3100/8800\n",
      "3200/8800\n",
      "3300/8800\n",
      "3400/8800\n",
      "3500/8800\n",
      "3600/8800\n",
      "3700/8800\n",
      "3800/8800\n",
      "3900/8800\n",
      "4000/8800\n",
      "4100/8800\n",
      "4200/8800\n",
      "4300/8800\n",
      "4400/8800\n",
      "4500/8800\n",
      "4600/8800\n",
      "4700/8800\n",
      "4800/8800\n",
      "4900/8800\n",
      "5000/8800\n",
      "5100/8800\n",
      "5200/8800\n",
      "5300/8800\n",
      "5400/8800\n",
      "5500/8800\n",
      "5600/8800\n",
      "5700/8800\n",
      "5800/8800\n",
      "5900/8800\n",
      "6000/8800\n",
      "6100/8800\n",
      "6200/8800\n",
      "6300/8800\n",
      "6400/8800\n",
      "6500/8800\n",
      "6600/8800\n",
      "6700/8800\n",
      "6800/8800\n",
      "6900/8800\n",
      "7000/8800\n",
      "7100/8800\n",
      "7200/8800\n",
      "7300/8800\n",
      "7400/8800\n",
      "7500/8800\n",
      "7600/8800\n",
      "7700/8800\n",
      "7800/8800\n",
      "7900/8800\n",
      "8000/8800\n",
      "8100/8800\n",
      "8200/8800\n",
      "8300/8800\n",
      "8400/8800\n",
      "8500/8800\n",
      "8600/8800\n",
      "8700/8800\n",
      "\n",
      " poetry\n",
      "   0/728\n",
      " 100/728\n",
      " 200/728\n",
      " 300/728\n",
      " 400/728\n",
      " 500/728\n",
      " 600/728\n",
      " 700/728\n",
      "\n",
      " taiga\n",
      "   0/881\n",
      " 100/881\n",
      " 200/881\n",
      " 300/881\n",
      " 400/881\n",
      " 500/881\n",
      " 600/881\n",
      " 700/881\n",
      " 800/881\n",
      "\n",
      "time results (s):\n",
      "gsd       : 12.119 (s)\n",
      "pud       : 21.383 (s)\n",
      "syntagrus : 172.897 (s)\n",
      "poetry    : 12.741 (s)\n",
      "taiga     : 13.954 (s)\n"
     ]
    }
   ],
   "source": [
    "!source /content/spacy_env/bin/activate; which python; python -m spacy download ru_core_news_lg; \\\n",
    "    python3 /content/parser_stat/parser_running.py /content/parser_stat/treebank_test_sets/treebank_data.pickle spacy_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "LlLn_O3j6Z73",
    "outputId": "b1a043b6-8c8f-4b41-dbde-6606049b8971"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_9f968f60-eaf1-4f7c-9584-01556e1e2b47\", \"spacy.pickle\", 15531898)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(\"/content/spacy_t.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_wOfNVh96cA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMj0sKs+1/xs4iTnejLte6/",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
