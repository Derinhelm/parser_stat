{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T22:18:24.781134Z",
     "iopub.status.busy": "2025-06-20T22:18:24.780278Z",
     "iopub.status.idle": "2025-06-20T22:18:24.811802Z",
     "shell.execute_reply": "2025-06-20T22:18:24.810854Z",
     "shell.execute_reply.started": "2025-06-20T22:18:24.781087Z"
    },
    "id": "mwS2uPLzrp8l"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jupyter/datasphere/project/parser_stat')\n",
    "sys.path.append('/home/jupyter/.local/lib/python3.11/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd8A4DmY5rdK"
   },
   "source": [
    "# Stanza running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T23:01:13.720168Z",
     "iopub.status.busy": "2025-06-20T23:01:13.719180Z",
     "iopub.status.idle": "2025-06-20T23:15:57.948615Z",
     "shell.execute_reply": "2025-06-20T23:15:57.947745Z",
     "shell.execute_reply.started": "2025-06-20T23:01:13.720137Z"
    },
    "id": "nZ9Q2cAu6LW4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting stanza==1.8.1\n",
      "  Downloading stanza-1.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: emoji in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (2.14.1)\n",
      "Requirement already satisfied: numpy in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (6.31.1)\n",
      "Requirement already satisfied: requests in /kernel/fallback/lib/python3.11/site-packages (from stanza==1.8.1) (2.31.0)\n",
      "Requirement already satisfied: networkx in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (3.5)\n",
      "Requirement already satisfied: toml in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /home/jupyter/.local/lib/python3.11/site-packages (from stanza==1.8.1) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/jupyter/.local/lib/python3.11/site-packages (from torch>=1.3.0->stanza==1.8.1) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /kernel/lib/python3.11/site-packages (from triton==3.3.1->torch>=1.3.0->stanza==1.8.1) (65.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jupyter/.local/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.3.0->stanza==1.8.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza==1.8.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /kernel/fallback/lib/python3.11/site-packages (from requests->stanza==1.8.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /kernel/fallback/lib/python3.11/site-packages (from requests->stanza==1.8.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /kernel/fallback/lib/python3.11/site-packages (from requests->stanza==1.8.1) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/fallback/lib/python3.11/site-packages (from requests->stanza==1.8.1) (2025.4.26)\n",
      "Downloading stanza-1.8.1-py3-none-any.whl (970 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.4/970.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: stanza\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed stanza-1.8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch==2.4.0\n",
      "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (4.14.0)\n",
      "Requirement already satisfied: sympy in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/jupyter/.local/lib/python3.11/site-packages (from torch==2.4.0) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0)\n",
      "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/jupyter/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jupyter/.local/lib/python3.11/site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.3.1\n",
      "\u001b[2K    Uninstalling triton-3.3.1:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.7713\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.770/13\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/13\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m 5/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu120m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1━━━━━━━━\u001b[0m \u001b[32m 9/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m 9/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m 9/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:90m━━━━━━━━━━━━\u001b[0m \u001b[32m 9/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2━━\u001b[0m \u001b[32m 9/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17━━━\u001b[0m \u001b[32m10/13\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.11m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.1:━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m12/13\u001b[0m [torch]nn-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m12/13\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m12/13\u001b[0m [torch]\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [torch]m12/13\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[33mWARNING: Ignoring invalid distribution -pacy (/home/jupyter/.local/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install stanza==1.8.1\n",
    "%pip install torch==2.4.0 --upgrade\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-06-21T04:51:14.014361Z",
     "iopub.status.busy": "2025-06-21T04:51:14.013497Z",
     "iopub.status.idle": "2025-06-21T08:08:20.592579Z",
     "shell.execute_reply": "2025-06-21T08:08:20.591449Z",
     "shell.execute_reply.started": "2025-06-21T04:51:14.014321Z"
    },
    "id": "yvGMAX2UlI5J",
    "outputId": "7b412b69-b81a-452a-cb1d-44d29d93befd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_stanza1.txt\n",
      "out_stanza2.txt\n",
      "out_stanza3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 10: source: not found\n",
      "2025-06-21 04:51:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 9.12MB/s]                    \n",
      "2025-06-21 04:51:18 INFO: Downloaded file to /home/jupyter/stanza_resources/resources.json\n",
      "2025-06-21 04:51:19 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| pos       | syntagrus_charlm   |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "| depparse  | syntagrus_charlm   |\n",
      "==================================\n",
      "\n",
      "2025-06-21 04:51:19 INFO: Using device: cpu\n",
      "2025-06-21 04:51:19 INFO: Loading: tokenize\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 04:51:21 INFO: Loading: pos\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/pos/trainer.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 04:51:21 INFO: Loading: lemma\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 04:51:21 INFO: Loading: depparse\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/depparse/trainer.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 04:51:22 INFO: Done loading processors!\n",
      "2025-06-21 05:57:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 12.2MB/s]                    \n",
      "2025-06-21 05:57:02 INFO: Downloaded file to /home/jupyter/stanza_resources/resources.json\n",
      "2025-06-21 05:57:03 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| pos       | syntagrus_charlm   |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "| depparse  | syntagrus_charlm   |\n",
      "==================================\n",
      "\n",
      "2025-06-21 05:57:03 INFO: Using device: cpu\n",
      "2025-06-21 05:57:03 INFO: Loading: tokenize\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 05:57:04 INFO: Loading: pos\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/pos/trainer.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 05:57:05 INFO: Loading: lemma\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 05:57:05 INFO: Loading: depparse\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/depparse/trainer.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 05:57:05 INFO: Done loading processors!\n",
      "2025-06-21 07:02:36 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 14.0MB/s]                    \n",
      "2025-06-21 07:02:36 INFO: Downloaded file to /home/jupyter/stanza_resources/resources.json\n",
      "2025-06-21 07:02:37 INFO: Loading these models for language: ru (Russian):\n",
      "==================================\n",
      "| Processor | Package            |\n",
      "----------------------------------\n",
      "| tokenize  | syntagrus          |\n",
      "| pos       | syntagrus_charlm   |\n",
      "| lemma     | syntagrus_nocharlm |\n",
      "| depparse  | syntagrus_charlm   |\n",
      "==================================\n",
      "\n",
      "2025-06-21 07:02:37 INFO: Using device: cpu\n",
      "2025-06-21 07:02:37 INFO: Loading: tokenize\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 07:02:39 INFO: Loading: pos\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/pos/trainer.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 07:02:39 INFO: Loading: lemma\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 07:02:39 INFO: Loading: depparse\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/stanza/models/depparse/trainer.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2025-06-21 07:02:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "!source /content/stanza_env/bin/activate; which python; \\\n",
    "    for i in 1 2 3; do export FP=\"out_stanza$i.txt\"; echo $FP; \\\n",
    "        python3 /home/jupyter/datasphere/project/parser_stat/parser_running.py /home/jupyter/datasphere/project/parser_stat/treebank_test_sets/treebank_data.pickle stanza > $FP; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
